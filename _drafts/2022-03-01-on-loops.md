---
layout: post
title:  "On The Relationship Between Recursion and Loops"
date:   2022-03-01
categories: loops functional-programming recursion
---

In the undergraduate computer science curriculum, we expend a
significant amount of time encouraging students to internalize the
relationship between recursion and iteration. In teaching my own
undergraduate programming (languages) class, I have observed
significant confusion and apprehension in using recursion. Here I
attempt to systematize what I see as several key idioms for loops in
functional programming.

Here is a high-level summary of my thoughts: the pattern of iterating
a computation to accumulate a value over a collection--using constant
stack space--is a common pattern we care about in practice, a good
price-point between a strictly-declarative interpretation of
programming (untethered by the worldly necessitites of running our
programs on large inputs and real hardware) and completely imperative
perspective. Central to the expression of loops is a notion of a set
of induction variables, a guard, and a body which will be executed
some number of times. When we allow ourselves just a single
implementation detail, *tail-calls*, we can clearly express the true
nature of loops--unbounded iteration in constant stack
space--harmoniously even in purely-functional languages.

## Simple Structurally-Recursive Functions

Most functional programming languages, statically typed or otherwise,
strongly emphasize programming via recursion and matching over
structurally-recursive data such as lists and trees. While
introductory examples of recursion (`fac`, `fib`, ...) appeal to
builtin types (such as numbers), the inductive structure of these
types may not be easily be observed in most programming languages
(notable exceptions include Coq, Agda, Lean, and other proof-oriented
languages), we will start with the simplest structurally-recursive
datatype: lists.

```
(define (sum lst)
  (match lst
    ['() 0]
	[`(,hd . ,tl) (+ hd (sum lst))]))
```

Notice that the function does its result by (a) destructs the list,
(b) makes a recursive a call to handle the tail (the observed value)
and (c) combines its result with the head by performing some
computation (in this case adding them). The function uses direct-style
recursion, in which the computer's stack is extended to perform the
recursive call to `sum`--and places a return point on the stack to
remember to continue to call `+` to add `hd` and the return value of
the recursive call. A large class of functions, the
[structurally-recursive
functions](https://en.wikipedia.org/wiki/Recursion_(computer_science)#Structural_versus_generative_recursion),
defined over lists (and similar algebraic datatypes) may be defined
this way. Because tuples are also a structurally-recursive type, this
is also true of functions that accept multiple inputs (e.g., `zip`,
`filter`, etc...). 

A more general type of recursion, [generative
recursion](https://htdp.org/2019-02-24/part_five.html), allows
building new inputs to the recursive call based on the destructed
value is necessary to express some algorithms (e.g.,
QuickSort). However, based on my own experience programming, I believe
the structurally-recursive functions comprise the vast majority of the
code we are likely to write in practice, and it is where I (and many
other courses I see) focus the bulk of my teaching efforts.

There is a significant tension, however, when it comes to teaching
loops: structurally-recursive functions to not immediately lead to
space-efficient solutions. For example, consider the Python function:

```
def sum(lst):
  r = 0
  for i in lst:
    r = r + i
```

This function uses a `for` loop. For loops, akin to many other
traditional looping constructs from imperative languages, have a
crucial property: they do not grow the stack. 

## A Common Pattern: Folds



## Parting Thoughts

I strongly believe that teaching students to relate iteration and
recursion, particularly tail recursion, is not a wasted
effort. However, I also would not go so far as to say that tail
recursion should be the cornerstone of most day-to-day code written by
functional programmers. Of course, many modern functional programming
languages use stackless compilation, or will simply grow the stack to
any size the user requires. Similarly, most of the code we write does
not operate over enormously-sized inputs that would justify the
kludginess of refactoring our code.

In the talk [Anatomy of a
Loop](https://www.youtube.com/watch?v=PCzNwWmQdb0), Olin Shivers makes
a point I had not at first appreciated: tail calls are goto, and their
use can quickly prove antithetical to the goals of functional
programming. I would argue that this is true, of course, in general.






I"Î'<p>It is well known that security policies for programs (such as
<a href="https://en.wikipedia.org/wiki/Non-interference_(security)">noninterference</a>) are not properties of a single run, but rather of
properties about sets of runs. For example, the following program uses
a so-called <em>implicit</em> flow to exfiltrate the value of its secret
input:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>input(secret)
if (secret == 0) then
    output(1)
else
    output(0)
</code></pre></div></div>

<p>This program is bad because it leaks something (one bit of knowledge)
about its input: whether or not it is zero. Informally, a program that
consumes a secret output and produces a publicly observable output is
only secure if that ouput is a constant. Because most programs that
produce constant outputs are not useful, this definition is often
upgraded to a program that takes a public and private input. The
program is then secure if ‚Äî for any <em>fixed</em> public input i·µñ
‚Äî and all secret inputs iÀ¢, the program produces a fixed output
o. Simple batch programs are boring and unrealistic, so there are a
number of ways in which we can upgrade these definitions to more
realistic programs. This is called noninterference, and it is not a
property of single executions, but rather a property of a <em>set</em> of
executions.</p>

<p>My intention with this post is to make the argument that we are not
being as systematic as we could be about constructing program analyses
based on our security definitions.</p>

<p><a href="https://www.cs.cornell.edu/fbs/publications/Hyperproperties.pdf">Hyperproperties</a> offer a general framework for discussing these
properties on sets of program exectuions.  But hyperproperties only
give us the means to define what it means for a program to be secure,
they don‚Äôt give us a tractable mechanism for checking program
security. It‚Äôs also worth noting that hyperproperties do have some
applications beyond merely security properties. They can reason about,
e.g., properties of concurrent executions or program
refinement. Clearly, the idea of checking sets of program executions
is not radical, but doing so has proved difficult and impractical.</p>

<p>To check programs for security definitions like noninterference, a
variety of mechanisms have been proposed. Perhaps the most popular in
the literature has been security-typed languages, where types encode
which information can flow to which sources and whose type systems
enforce the security gaurentee. <a href="http://www.cs.cornell.edu/jif/">Jif</a> and <a href="https://hackage.haskell.org/package/lio">lio</a> are notable examples
that fall into this category.</p>

<p>Checking properties about programs has a rich history in programming
languages, that have established a variety of fields: static analysis,
type theory, and model checking to name a few. Most of these
techniques were originally developed with the intention of checking
facts about single-run program properties (e.g., pointer analysis,
taint analysis, etc..). Applying them to security is often nonobvious,
because they have to be adapted to talk about <em>sets</em> of program runs.</p>

<p>Figuring out how to upgrade our single-run techniques to reason about
sets of runs has been the theme of a lot of security research:</p>

<ul>
  <li>
    <p>Security type systems (like the ones in Jif) use type-based
techniques to give a composable way to reason about security of a
program from smaller components, just as type systems have done for
traditional properties like type correctness and resource usage
(linear logic).</p>
  </li>
  <li>
    <p><a href="https://users.soe.ucsc.edu/~cormac/papers/popl12b.pdf">Faceted execution</a>
(as seen in languages like
<a href="https://projects.csail.mit.edu/jeeves/">Jeeves</a>) is a method of
enforcing program security dynamically. It uses an upgraded form of
taint tracking to reason about what information has influenced
computation of variables. Then it uses this to show observers a view
of the computation that ensures they don‚Äôt learn secret inputs. This
is analogous to inline reference monitors for policies like ‚Äúthe
network can never be accessed after the file is read.‚Äù</p>
  </li>
  <li>
    <p>Relational program verifiection reasons about pairs of program
components (like functions that manipulate heaps) in isolation and
glues them together using composition. An example of this is
<a href="http://research.microsoft.com/apps/pubs/default.aspx?id=204802">Relational F*</a>,
which uses dependent types to specify program behavior on pairs of
input states and relates their output states.</p>
  </li>
  <li>
    <p><a href="http://www.cs.cornell.edu/~clarkson/papers/clarkson_hyper_tl.pdf">Hyper temporal logics</a>
levels up standard notions of model checking to apply them to
checking temporal logic hyperproperties. That work includes a notion
of model checking that begins by taking the program and modeling it
as a state space of a single execution, and then runs a product
semantics for it, showing how to systematically use this semantics
to check hyper properties about temporal assertions on state
sets. This allows a rich encoding for many trace-based
hyperoproperties such as generalized noninterference and
observational determinism.</p>
  </li>
</ul>

<h2 id="the-future-push-button-security-checking">The Future: Push Button Security Checking</h2>

<p>One thing that I think is lacking in security currently is that our
analyses are only tenuously tied to the properties we want to
check. There‚Äôs no systematic way to go from a semantics and fact to a
way to check facts about those properties for programs. Instead, we
see lots of one-off security definitions, and lots of tools for
checking definitions, but we rarely see security statements along with
a systematically derived mechanism to check facts about those
programs. This is an area I think we as a field could improve on.</p>

<p>Within PL, the
<a href="http://matt.might.net/papers/vanhorn2010abstract.pdf">abstracting abstracting machines</a>
technique to deriving abstract interpreters has this flavor. You find
the semantics you want to check, bake in the facts you want to check,
and then systematically derive an abstract interpreter in a cookbook
style. But we have no such bushbutton methodology for checking
security properties of programs. As a designer of a system for
security today, you have to read the vast literature on the set of
security properties you might want to check, find one that suits you,
and <em>then</em> dream up an enforcement technique for whatever language you
want to work with.</p>

<p>I‚Äôm not sure exactly what this would look like. But I think it‚Äôs going
to be something like this: write down the semantics for the program
you want, and then manipulate the semantics in some way to get a state
space representing what you want. Then, perform a simple abstraction
over that state space to get the properties you want to check.</p>

<p>Here‚Äôs how I think this might work. First, you could imagine taking
your semantics and simply running it in parallel with another version
of the program, so that the concrete state space is now a product
space. Hyperproperties that rely on program pairs can be specified
using sets of concrete runs. Now abstract the program using our AAM
trick and get an abstract state space that is lifted to each component
of the pair. Abstract states concretize to pairs of concrete runs, and
now checking properties of executions means extending these properties
to work on our abstract domain, however they are represented. E.g., if
they are represented as symbolic states in a symbolic executor, you
would write symbolic formulas asserting noninterference, though
certainly other forms are possible. It‚Äôs also worth noting that this
works for more than just pairs, you could also imagine doing it for
triples to check properties like generalized noninterference.</p>

<p>The abstraction technique I proposed is running a product program and
then doing the abstraction pointwise over each pair component. I think
this is a good first cut because it is easier to see how it relates to
the extensional property we want to check: simply check the property
by concretizing each point in the abstract state product and running
it through the formula. I‚Äôm not sure whether or not this technique
will scale to larger programs.</p>

<p>One thing that‚Äôs missing from this technique is that the abstraction
doesn‚Äôt know anything about the property we want to check, the
abstraction is simply pointwise and the abstract domain hasn‚Äôt been
efficiently engineered to be tailored to semantic knowlege about the
program. But I think this is the right place to start, because it
gives us an intuitive baseline for our abstraction.</p>

<p>Let‚Äôs say that we want to level this technique up. We would want an
abstraction that <em>does</em> know things about how the program is
operating. Here‚Äôs how I think we might do that for the specific case
of noninterference checking: run the original program under a faceted
execution semantics with faceted values for the inputs we care
about. The faceted semantics is implicitly unrolling this product
program when it needs to to gaurentee that our security needs are
met. If we want to check whether the program is secure, we simply need
to look at the output and ask whether or not it is a faceted value. If
it is, we still might be able to do something. Let‚Äôs say, for example,
that we can prove the faceted value produces the same result no matter
what the principle. If we can do this, we can still gaurentee the
program doesn‚Äôt leak any information.</p>

<p>I‚Äôm not sure why this intuition holds, but I have a feeling that it‚Äôs
because the facet refines the ‚Äúdumb‚Äù product semantics so that it does
the product behavior only when necessary. Frankly, I‚Äôm not sure if
this single case generalizes to the intuition about other sorts of
hyperproperties. But I this story of systematically deriving abstract
interpreters for security properties is very appealing, and one that
we should continue to push on.</p>

:ET